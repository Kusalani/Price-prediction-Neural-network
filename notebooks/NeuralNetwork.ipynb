{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 10:39:14.148398: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-29 10:39:14.179803: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-29 10:39:14.179845: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-29 10:39:14.179880: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-29 10:39:14.186669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-29 10:39:14.187645: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-29 10:39:15.089358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from hyperopt import fmin, tpe, hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset into the Data Frame\n",
    "df = pd.read_csv('../data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>GemstoneName</th>\n",
       "      <th>Color</th>\n",
       "      <th>Clarity</th>\n",
       "      <th>Cut</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Spinel</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Oval</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Cat's Eye</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Translucent</td>\n",
       "      <td>Oval</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>Spinel</td>\n",
       "      <td>Brown</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Oval</td>\n",
       "      <td>1.36</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-28</td>\n",
       "      <td>Cat's Eye</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>Translucent</td>\n",
       "      <td>Oval</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>Sapphire</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>0.73</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Red</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>0.51</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Red</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>0.95</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Oval</td>\n",
       "      <td>0.73</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Purple</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Oval</td>\n",
       "      <td>0.73</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>2022-03-21</td>\n",
       "      <td>Ruby</td>\n",
       "      <td>Red</td>\n",
       "      <td>Transparent</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>0.95</td>\n",
       "      <td>30500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>701 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date GemstoneName   Color      Clarity      Cut  Weight  Price\n",
       "0    2021-01-15       Spinel   Brown  Transparent     Oval    1.36   9000\n",
       "1    2021-01-15    Cat's Eye  Yellow  Translucent     Oval    0.75  18000\n",
       "2    2021-01-17       Spinel   Brown  Transparent     Oval    1.36   9000\n",
       "3    2021-01-28    Cat's Eye  Yellow  Translucent     Oval    0.75  18000\n",
       "4    2021-02-12     Sapphire  Purple  Transparent  Emerald    0.73  20000\n",
       "..          ...          ...     ...          ...      ...     ...    ...\n",
       "696  2022-05-11         Ruby     Red  Transparent  Emerald    0.51  30000\n",
       "697  2022-08-04         Ruby     Red  Transparent  Emerald    0.95  30000\n",
       "698  2022-09-20         Ruby  Purple  Transparent     Oval    0.73  30000\n",
       "699  2023-01-17         Ruby  Purple  Transparent     Oval    0.73  30000\n",
       "700  2022-03-21         Ruby     Red  Transparent  Emerald    0.95  30500\n",
       "\n",
       "[701 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features\n",
    "categorical_columns = ['GemstoneName','Color' , 'Clarity','Cut']\n",
    "for column in categorical_columns:\n",
    "    df[column] = LabelEncoder().fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "df['Date'] = pd.to_datetime(df['Date'])  # Convert 'Date' column to datetime\n",
    "df.set_index('Date', inplace=True)  # Set 'Date' as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = df.drop(columns=['Price'])\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a hyperparameter search space\n",
    "space = {\n",
    "    'n_hidden_layers': hp.choice('n_hidden_layers', [1, 2, 3]),\n",
    "    'n_units': hp.choice('n_units', [64, 128, 256]),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, -2),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.0, 0.5),\n",
    "    'epochs': hp.quniform('epochs', 50, 200, 10),\n",
    "    'batch_size': hp.choice('batch_size', [32, 64, 128])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for hyperparameter tuning\n",
    "def objective(params):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "    \n",
    "    for _ in range(params['n_hidden_layers']):\n",
    "        model.add(keras.layers.Dense(params['n_units'], activation='relu'))\n",
    "        model.add(keras.layers.Dropout(params['dropout_rate']))\n",
    "    \n",
    "    model.add(keras.layers.Dense(1))  # Output layer for regression\n",
    "    \n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "                  loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=int(params['epochs']), batch_size=params['batch_size'], verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s         \n",
      "5/5 [==============================] - 0s 2ms/step    \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 1ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 1ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                   \n",
      "5/5 [==============================] - 0s 2ms/step                              \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 1ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "1/5 [=====>........................] - ETA: 0s                                    \n",
      "5/5 [==============================] - 0s 2ms/step                               \n",
      "\n",
      "100%|██████████| 100/100 [05:06<00:00,  3.06s/trial, best loss: 24146.906968493062]\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter tuning using Hyperopt\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with the best hyperparameters\n",
    "final_model = keras.Sequential()\n",
    "final_model.add(keras.layers.Input(shape=(X_train.shape[1],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n",
      "560/560 [==============================] - 1s 959us/step - loss: 9988321280.0000\n",
      "Epoch 2/160\n",
      "560/560 [==============================] - 1s 941us/step - loss: 9984545792.0000\n",
      "Epoch 3/160\n",
      "560/560 [==============================] - 1s 965us/step - loss: 9980821504.0000\n",
      "Epoch 4/160\n",
      "560/560 [==============================] - 1s 911us/step - loss: 9977064448.0000\n",
      "Epoch 5/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9973286912.0000\n",
      "Epoch 6/160\n",
      "560/560 [==============================] - 1s 958us/step - loss: 9969505280.0000\n",
      "Epoch 7/160\n",
      "560/560 [==============================] - 1s 916us/step - loss: 9965753344.0000\n",
      "Epoch 8/160\n",
      "560/560 [==============================] - 1s 920us/step - loss: 9962012672.0000\n",
      "Epoch 9/160\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 9958277120.0000\n",
      "Epoch 10/160\n",
      "560/560 [==============================] - 1s 984us/step - loss: 9954526208.0000\n",
      "Epoch 11/160\n",
      "560/560 [==============================] - 1s 932us/step - loss: 9950773248.0000\n",
      "Epoch 12/160\n",
      "560/560 [==============================] - 1s 925us/step - loss: 9947040768.0000\n",
      "Epoch 13/160\n",
      "560/560 [==============================] - 1s 938us/step - loss: 9943318528.0000\n",
      "Epoch 14/160\n",
      "560/560 [==============================] - 1s 941us/step - loss: 9939579904.0000\n",
      "Epoch 15/160\n",
      "560/560 [==============================] - 1s 941us/step - loss: 9935863808.0000\n",
      "Epoch 16/160\n",
      "560/560 [==============================] - 1s 927us/step - loss: 9932133376.0000\n",
      "Epoch 17/160\n",
      "560/560 [==============================] - 1s 924us/step - loss: 9928386560.0000\n",
      "Epoch 18/160\n",
      "560/560 [==============================] - 1s 938us/step - loss: 9924633600.0000\n",
      "Epoch 19/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9920900096.0000\n",
      "Epoch 20/160\n",
      "560/560 [==============================] - 1s 962us/step - loss: 9917181952.0000\n",
      "Epoch 21/160\n",
      "560/560 [==============================] - 1s 948us/step - loss: 9913475072.0000\n",
      "Epoch 22/160\n",
      "560/560 [==============================] - 1s 943us/step - loss: 9909765120.0000\n",
      "Epoch 23/160\n",
      "560/560 [==============================] - 1s 931us/step - loss: 9906048000.0000\n",
      "Epoch 24/160\n",
      "560/560 [==============================] - 1s 915us/step - loss: 9902323712.0000\n",
      "Epoch 25/160\n",
      "560/560 [==============================] - 1s 935us/step - loss: 9898608640.0000\n",
      "Epoch 26/160\n",
      "560/560 [==============================] - 1s 966us/step - loss: 9894898688.0000\n",
      "Epoch 27/160\n",
      "560/560 [==============================] - 1s 923us/step - loss: 9891191808.0000\n",
      "Epoch 28/160\n",
      "560/560 [==============================] - 1s 958us/step - loss: 9887474688.0000\n",
      "Epoch 29/160\n",
      "560/560 [==============================] - 1s 973us/step - loss: 9883772928.0000\n",
      "Epoch 30/160\n",
      "560/560 [==============================] - 1s 946us/step - loss: 9880097792.0000\n",
      "Epoch 31/160\n",
      "560/560 [==============================] - 1s 920us/step - loss: 9876408320.0000\n",
      "Epoch 32/160\n",
      "560/560 [==============================] - 1s 948us/step - loss: 9872704512.0000\n",
      "Epoch 33/160\n",
      "560/560 [==============================] - 1s 925us/step - loss: 9869001728.0000\n",
      "Epoch 34/160\n",
      "560/560 [==============================] - 1s 964us/step - loss: 9865310208.0000\n",
      "Epoch 35/160\n",
      "560/560 [==============================] - 1s 914us/step - loss: 9861665792.0000\n",
      "Epoch 36/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9857999872.0000\n",
      "Epoch 37/160\n",
      "560/560 [==============================] - 1s 912us/step - loss: 9854314496.0000\n",
      "Epoch 38/160\n",
      "560/560 [==============================] - 1s 945us/step - loss: 9850635264.0000\n",
      "Epoch 39/160\n",
      "560/560 [==============================] - 1s 952us/step - loss: 9846942720.0000\n",
      "Epoch 40/160\n",
      "560/560 [==============================] - 1s 915us/step - loss: 9843263488.0000\n",
      "Epoch 41/160\n",
      "560/560 [==============================] - 1s 915us/step - loss: 9839597568.0000\n",
      "Epoch 42/160\n",
      "560/560 [==============================] - 1s 947us/step - loss: 9835948032.0000\n",
      "Epoch 43/160\n",
      "560/560 [==============================] - 1s 931us/step - loss: 9832293376.0000\n",
      "Epoch 44/160\n",
      "560/560 [==============================] - 1s 951us/step - loss: 9828630528.0000\n",
      "Epoch 45/160\n",
      "560/560 [==============================] - 1s 957us/step - loss: 9824982016.0000\n",
      "Epoch 46/160\n",
      "560/560 [==============================] - 1s 940us/step - loss: 9821316096.0000\n",
      "Epoch 47/160\n",
      "560/560 [==============================] - 1s 924us/step - loss: 9817658368.0000\n",
      "Epoch 48/160\n",
      "560/560 [==============================] - 1s 986us/step - loss: 9814021120.0000\n",
      "Epoch 49/160\n",
      "560/560 [==============================] - 1s 998us/step - loss: 9810396160.0000\n",
      "Epoch 50/160\n",
      "560/560 [==============================] - 1s 952us/step - loss: 9806746624.0000\n",
      "Epoch 51/160\n",
      "560/560 [==============================] - 1s 937us/step - loss: 9803079680.0000\n",
      "Epoch 52/160\n",
      "560/560 [==============================] - 1s 935us/step - loss: 9799404544.0000\n",
      "Epoch 53/160\n",
      "560/560 [==============================] - 1s 928us/step - loss: 9795792896.0000\n",
      "Epoch 54/160\n",
      "560/560 [==============================] - 1s 954us/step - loss: 9792179200.0000\n",
      "Epoch 55/160\n",
      "560/560 [==============================] - 1s 927us/step - loss: 9788517376.0000\n",
      "Epoch 56/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9784902656.0000\n",
      "Epoch 57/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9781251072.0000\n",
      "Epoch 58/160\n",
      "560/560 [==============================] - 1s 966us/step - loss: 9777585152.0000\n",
      "Epoch 59/160\n",
      "560/560 [==============================] - 1s 934us/step - loss: 9773959168.0000\n",
      "Epoch 60/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9770366976.0000\n",
      "Epoch 61/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9766769664.0000\n",
      "Epoch 62/160\n",
      "560/560 [==============================] - 1s 957us/step - loss: 9763160064.0000\n",
      "Epoch 63/160\n",
      "560/560 [==============================] - 1s 946us/step - loss: 9759553536.0000\n",
      "Epoch 64/160\n",
      "560/560 [==============================] - 1s 918us/step - loss: 9755939840.0000\n",
      "Epoch 65/160\n",
      "560/560 [==============================] - 1s 928us/step - loss: 9752343552.0000\n",
      "Epoch 66/160\n",
      "560/560 [==============================] - 1s 923us/step - loss: 9748733952.0000\n",
      "Epoch 67/160\n",
      "560/560 [==============================] - 1s 964us/step - loss: 9745120256.0000\n",
      "Epoch 68/160\n",
      "560/560 [==============================] - 1s 966us/step - loss: 9741515776.0000\n",
      "Epoch 69/160\n",
      "560/560 [==============================] - 1s 935us/step - loss: 9737890816.0000\n",
      "Epoch 70/160\n",
      "560/560 [==============================] - 1s 918us/step - loss: 9734300672.0000\n",
      "Epoch 71/160\n",
      "560/560 [==============================] - 1s 913us/step - loss: 9730707456.0000\n",
      "Epoch 72/160\n",
      "560/560 [==============================] - 1s 931us/step - loss: 9727097856.0000\n",
      "Epoch 73/160\n",
      "560/560 [==============================] - 1s 999us/step - loss: 9723509760.0000\n",
      "Epoch 74/160\n",
      "560/560 [==============================] - 1s 928us/step - loss: 9719929856.0000\n",
      "Epoch 75/160\n",
      "560/560 [==============================] - 1s 922us/step - loss: 9716335616.0000\n",
      "Epoch 76/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9712736256.0000\n",
      "Epoch 77/160\n",
      "560/560 [==============================] - 1s 955us/step - loss: 9709168640.0000\n",
      "Epoch 78/160\n",
      "560/560 [==============================] - 1s 985us/step - loss: 9705604096.0000\n",
      "Epoch 79/160\n",
      "560/560 [==============================] - 1s 908us/step - loss: 9702049792.0000\n",
      "Epoch 80/160\n",
      "560/560 [==============================] - 1s 920us/step - loss: 9698454528.0000\n",
      "Epoch 81/160\n",
      "560/560 [==============================] - 1s 930us/step - loss: 9694894080.0000\n",
      "Epoch 82/160\n",
      "560/560 [==============================] - 1s 958us/step - loss: 9691350016.0000\n",
      "Epoch 83/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9687768064.0000\n",
      "Epoch 84/160\n",
      "560/560 [==============================] - 1s 923us/step - loss: 9684197376.0000\n",
      "Epoch 85/160\n",
      "560/560 [==============================] - 1s 929us/step - loss: 9680645120.0000\n",
      "Epoch 86/160\n",
      "560/560 [==============================] - 1s 915us/step - loss: 9677063168.0000\n",
      "Epoch 87/160\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 9673504768.0000\n",
      "Epoch 88/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9669961728.0000\n",
      "Epoch 89/160\n",
      "560/560 [==============================] - 1s 934us/step - loss: 9666416640.0000\n",
      "Epoch 90/160\n",
      "560/560 [==============================] - 1s 912us/step - loss: 9662884864.0000\n",
      "Epoch 91/160\n",
      "560/560 [==============================] - 1s 910us/step - loss: 9659328512.0000\n",
      "Epoch 92/160\n",
      "560/560 [==============================] - 1s 942us/step - loss: 9655778304.0000\n",
      "Epoch 93/160\n",
      "560/560 [==============================] - 1s 941us/step - loss: 9652240384.0000\n",
      "Epoch 94/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9648688128.0000\n",
      "Epoch 95/160\n",
      "560/560 [==============================] - 1s 908us/step - loss: 9645167616.0000\n",
      "Epoch 96/160\n",
      "560/560 [==============================] - 1s 918us/step - loss: 9641654272.0000\n",
      "Epoch 97/160\n",
      "560/560 [==============================] - 1s 976us/step - loss: 9638107136.0000\n",
      "Epoch 98/160\n",
      "560/560 [==============================] - 1s 940us/step - loss: 9634579456.0000\n",
      "Epoch 99/160\n",
      "560/560 [==============================] - 1s 918us/step - loss: 9631032320.0000\n",
      "Epoch 100/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9627481088.0000\n",
      "Epoch 101/160\n",
      "560/560 [==============================] - 1s 931us/step - loss: 9623942144.0000\n",
      "Epoch 102/160\n",
      "560/560 [==============================] - 1s 969us/step - loss: 9620431872.0000\n",
      "Epoch 103/160\n",
      "560/560 [==============================] - 1s 915us/step - loss: 9616897024.0000\n",
      "Epoch 104/160\n",
      "560/560 [==============================] - 1s 922us/step - loss: 9613410304.0000\n",
      "Epoch 105/160\n",
      "560/560 [==============================] - 1s 940us/step - loss: 9609909248.0000\n",
      "Epoch 106/160\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 9606387712.0000\n",
      "Epoch 107/160\n",
      "560/560 [==============================] - 1s 958us/step - loss: 9602885632.0000\n",
      "Epoch 108/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9599369216.0000\n",
      "Epoch 109/160\n",
      "560/560 [==============================] - 1s 947us/step - loss: 9595854848.0000\n",
      "Epoch 110/160\n",
      "560/560 [==============================] - 1s 922us/step - loss: 9592361984.0000\n",
      "Epoch 111/160\n",
      "560/560 [==============================] - 1s 936us/step - loss: 9588881408.0000\n",
      "Epoch 112/160\n",
      "560/560 [==============================] - 1s 946us/step - loss: 9585385472.0000\n",
      "Epoch 113/160\n",
      "560/560 [==============================] - 1s 945us/step - loss: 9581895680.0000\n",
      "Epoch 114/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9578387456.0000\n",
      "Epoch 115/160\n",
      "560/560 [==============================] - 1s 927us/step - loss: 9574916096.0000\n",
      "Epoch 116/160\n",
      "560/560 [==============================] - 1s 957us/step - loss: 9571451904.0000\n",
      "Epoch 117/160\n",
      "560/560 [==============================] - 1s 940us/step - loss: 9567976448.0000\n",
      "Epoch 118/160\n",
      "560/560 [==============================] - 1s 918us/step - loss: 9564497920.0000\n",
      "Epoch 119/160\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 9561010176.0000\n",
      "Epoch 120/160\n",
      "560/560 [==============================] - 1s 918us/step - loss: 9557528576.0000\n",
      "Epoch 121/160\n",
      "560/560 [==============================] - 1s 955us/step - loss: 9554043904.0000\n",
      "Epoch 122/160\n",
      "560/560 [==============================] - 1s 940us/step - loss: 9550573568.0000\n",
      "Epoch 123/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9547099136.0000\n",
      "Epoch 124/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9543604224.0000\n",
      "Epoch 125/160\n",
      "560/560 [==============================] - 1s 945us/step - loss: 9540117504.0000\n",
      "Epoch 126/160\n",
      "560/560 [==============================] - 1s 1ms/step - loss: 9536655360.0000\n",
      "Epoch 127/160\n",
      "560/560 [==============================] - 1s 926us/step - loss: 9533218816.0000\n",
      "Epoch 128/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9529788416.0000\n",
      "Epoch 129/160\n",
      "560/560 [==============================] - 1s 938us/step - loss: 9526331392.0000\n",
      "Epoch 130/160\n",
      "560/560 [==============================] - 1s 934us/step - loss: 9522855936.0000\n",
      "Epoch 131/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9519394816.0000\n",
      "Epoch 132/160\n",
      "560/560 [==============================] - 1s 935us/step - loss: 9515939840.0000\n",
      "Epoch 133/160\n",
      "560/560 [==============================] - 1s 946us/step - loss: 9512484864.0000\n",
      "Epoch 134/160\n",
      "560/560 [==============================] - 1s 941us/step - loss: 9509060608.0000\n",
      "Epoch 135/160\n",
      "560/560 [==============================] - 1s 976us/step - loss: 9505641472.0000\n",
      "Epoch 136/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9502208000.0000\n",
      "Epoch 137/160\n",
      "560/560 [==============================] - 1s 933us/step - loss: 9498752000.0000\n",
      "Epoch 138/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9495309312.0000\n",
      "Epoch 139/160\n",
      "560/560 [==============================] - 1s 908us/step - loss: 9491887104.0000\n",
      "Epoch 140/160\n",
      "560/560 [==============================] - 1s 947us/step - loss: 9488472064.0000\n",
      "Epoch 141/160\n",
      "560/560 [==============================] - 1s 924us/step - loss: 9485075456.0000\n",
      "Epoch 142/160\n",
      "560/560 [==============================] - 1s 939us/step - loss: 9481626624.0000\n",
      "Epoch 143/160\n",
      "560/560 [==============================] - 1s 917us/step - loss: 9478176768.0000\n",
      "Epoch 144/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9474761728.0000\n",
      "Epoch 145/160\n",
      "560/560 [==============================] - 1s 975us/step - loss: 9471357952.0000\n",
      "Epoch 146/160\n",
      "560/560 [==============================] - 1s 975us/step - loss: 9467940864.0000\n",
      "Epoch 147/160\n",
      "560/560 [==============================] - 1s 915us/step - loss: 9464528896.0000\n",
      "Epoch 148/160\n",
      "560/560 [==============================] - 1s 928us/step - loss: 9461132288.0000\n",
      "Epoch 149/160\n",
      "560/560 [==============================] - 1s 936us/step - loss: 9457723392.0000\n",
      "Epoch 150/160\n",
      "560/560 [==============================] - 1s 919us/step - loss: 9454310400.0000\n",
      "Epoch 151/160\n",
      "560/560 [==============================] - 1s 908us/step - loss: 9450908672.0000\n",
      "Epoch 152/160\n",
      "560/560 [==============================] - 1s 964us/step - loss: 9447503872.0000\n",
      "Epoch 153/160\n",
      "560/560 [==============================] - 1s 921us/step - loss: 9444107264.0000\n",
      "Epoch 154/160\n",
      "560/560 [==============================] - 1s 929us/step - loss: 9440726016.0000\n",
      "Epoch 155/160\n",
      "560/560 [==============================] - 1s 943us/step - loss: 9437326336.0000\n",
      "Epoch 156/160\n",
      "560/560 [==============================] - 1s 934us/step - loss: 9433948160.0000\n",
      "Epoch 157/160\n",
      "560/560 [==============================] - 1s 916us/step - loss: 9430550528.0000\n",
      "Epoch 158/160\n",
      "560/560 [==============================] - 1s 960us/step - loss: 9427173376.0000\n",
      "Epoch 159/160\n",
      "560/560 [==============================] - 1s 950us/step - loss: 9423804416.0000\n",
      "Epoch 160/160\n",
      "560/560 [==============================] - 1s 935us/step - loss: 9420414976.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fbd6872f400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in range(best['n_hidden_layers']):\n",
    "    final_model.add(keras.layers.Dense(best['n_units'], activation='relu'))\n",
    "    final_model.add(keras.layers.Dropout(best['dropout_rate']))\n",
    "\n",
    "final_model.add(keras.layers.Dense(1))\n",
    "\n",
    "final_model.compile(optimizer=keras.optimizers.Adam(learning_rate=best['learning_rate']),\n",
    "                    loss='mean_squared_error')\n",
    "\n",
    "final_model.fit(X_train, y_train, epochs=int(best['epochs']), batch_size=best['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb Cell 15\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Evaluate the final model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_loss \u001b[39m=\u001b[39m final_model\u001b[39m.\u001b[39mevaluate(X_test, y_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTest RMSE: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39msqrt(test_loss)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the final model\n",
    "test_loss = final_model.evaluate(X_test, y_test)\n",
    "print(f\"Test RMSE: {np.sqrt(test_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Assuming you have trained and evaluated your final model as 'final_model'\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Save the model to a file\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bpsychic-winner-rqv4v46pgjhxgg4/workspaces/Price-prediction-Neural-network/notebooks/NeuralNetwork.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m final_model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mgemstone_price_prediction_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have trained and evaluated your final model as 'final_model'\n",
    "\n",
    "# Save the model to a file\n",
    "final_model.save('gemstone_price_prediction_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicted Gemstone Price: $4449.20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the trained model\n",
    "loaded_model = keras.models.load_model('gemstone_price_prediction_model.h5')\n",
    "\n",
    "# Collect user input\n",
    "gemstone_name = input(\"Enter the gemstone name: \")\n",
    "cut = input(\"Enter the cut: \")\n",
    "color = input(\"Enter the color: \")\n",
    "clarity = input(\"Enter the clarity: \")\n",
    "weight = float(input(\"Enter the weight: \"))\n",
    "\n",
    "# Create a DataFrame with the user input\n",
    "user_input = pd.DataFrame({\n",
    "    'gemstone_name': [gemstone_name],\n",
    "    'cut': [cut],\n",
    "    'color': [color],\n",
    "    'clarity': [clarity],\n",
    "    'weight': [weight]\n",
    "})\n",
    "\n",
    "# Perform data preprocessing on the user input (similar to the training data)\n",
    "categorical_columns = ['gemstone_name', 'cut', 'color', 'clarity']\n",
    "for column in categorical_columns:\n",
    "    user_input[column] = LabelEncoder().fit_transform(user_input[column])\n",
    "\n",
    "numerical_columns = ['weight']\n",
    "scaler = StandardScaler()\n",
    "user_input[numerical_columns] = scaler.fit_transform(user_input[numerical_columns])\n",
    "\n",
    "# Convert the input array to a float32 array\n",
    "user_input = user_input.astype('float32')\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "predicted_prices = loaded_model.predict(user_input.values)\n",
    "\n",
    "# Display the predicted price\n",
    "predicted_price = predicted_prices[0][0]\n",
    "print(f'Predicted Gemstone Price: ${predicted_price:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
